# âš¡ Grid Operations AI Assistant  

An AI-powered assistant for managing **grid operations**, including electricity consumption forecasting, capacity planning, generation monitoring, and load optimization.  
It leverages a **Retrieval-Augmented Generation (RAG)** pipeline to provide **grounded, data-driven insights** from historical energy consumption records.  

---

## ğŸ”‘ Key Features  

- **Load Forecasting** â€“ Predict future electricity demand for specific cities or areas based on historical data.  
- **Capacity Planning** â€“ Calculate the necessary prepared energy capacity for the next 3 hours, considering a reserve margin and historical consumption patterns.  
- **Generation Monitoring** â€“ Analyze real-time generation data from distributed sources and automatically flag anomalies or shortfalls.  
- **Load Optimization** â€“ Recommend concrete, sector-specific actions to balance supply and demand and prevent power outages.  
- **Consumption Analysis** â€“ Dive deep into historical data to identify key consumption trends, peak hours, and low-usage periods.  
- **Historical Similarity Search** â€“ Find days with similar consumption patterns to a target date, helping operators understand past behavior under comparable conditions.  

---

## ğŸ› ï¸ Technology Stack  

- **Framework**: [FastMCP](https://github.com/) (based on FastAPI) for building the agentâ€™s server.  
- **AI/ML**:  
  - [IBM watsonx.ai](https://www.ibm.com/watsonx/ai) â€“ Core LLM for reasoning, analysis, and generation.  
  - [LangChain](https://www.langchain.com/) â€“ Orchestrates the RAG pipeline.  
  - [FAISS](https://github.com/facebookresearch/faiss) â€“ Vector database for similarity search.  
  - [Sentence-Transformers](https://www.sbert.net/) â€“ Generates embeddings for historical data.  
- **Data Handling**: [pandas](https://pandas.pydata.org/) for manipulation, [matplotlib](https://matplotlib.org/) for visualizations.  
- **Utilities**: [python-dotenv](https://github.com/theskumar/python-dotenv) for environment variable management.  

---

## âš™ï¸ Installation and Setup  

### ğŸ“‚ Project Structure
```bash
â”œâ”€â”€ sample_data/
â”‚   â””â”€â”€ load_history1.csv   # historical energy data
â”œâ”€â”€ flask_app.py            # main agent server
â”œâ”€â”€ rag_pipeline.py         # RAG pipeline logic
â”œâ”€â”€ requirements.txt        # dependencies
â”œâ”€â”€ constraints.txt         # dependency constraints
â””â”€â”€ README.md               # this file
```

### 1. Clone the repository  
```bash
git clone <repository_url>
cd <repository_folder>
```
### 2. Install dependencies
This project uses a constraints file (constraints.txt) for consistent dependency resolution.
```bash
pip install -r requirements.txt -c constraints.txt --upgrade
```
### 3. Configure API credentials
Create a .env file in the project root:
```ini
# .env
WATSONX_API_KEY="<your_api_key>"
WATSONX_PROJECT_ID="<your_project_id>"
WATSONX_URL="https://us-south.ml.cloud.ibm.com"  # Or your specific endpoint
```
### 4. Prepare data
Place your historical energy consumption data in:
```bash
sample_data/load_history1.csv
```

## ğŸš€ How to Run

Start the agent server:
```bash
python flask_app.py
```
view the UI on 
```bash
http://127.0.0.1:5000/
```
## ğŸ§  Core Concepts

### The intelligence of this app comes from its RAG pipeline:

#### Ingestion â€“ RAGPipeline reads historical energy data (CSV â†’ Document objects â†’ Embeddings).

#### Vectorstore â€“ Embeddings stored in FAISS, supporting:

#### Raw energy consumption data

#### Aggregated daily patterns

#### Retrieval â€“ Queries retrieve similar historical data and patterns.

#### Generation â€“ Retrieved context + user request â†’ sent to IBM watsonx.ai LLM, which produces grounded forecasts, analyses, or actionable recommendations.
